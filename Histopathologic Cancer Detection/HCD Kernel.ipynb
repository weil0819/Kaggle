{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 0. Configure Package Dependencies "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np \nimport pandas as pd\nimport shutil\nfrom glob import glob \nimport os\nimport cv2\nimport gc    # garbage collection, we need to save all the RAM we can\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Flatten, Dense, AveragePooling2D, Dropout, BatchNormalization, Activation, Conv2D, MaxPool2D\nfrom keras.models import Model\nfrom keras.optimizers import RMSprop, SGD\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm_notebook,trange  # a minimalistic yet powerful and easy to use progress bar\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Import the Dataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/histopathologic-cancer-detection/'           # data files \ntrain_dir = path + 'train/'  # training data directory\ntest_dir = path + 'test/'    # testing data directory\n\ntrain = pd.DataFrame({'path':glob(os.path.join(train_dir,'*.tif'))})\ntrain['id'] = train.path.map(lambda x: x.split('/')[4].split('.')[0]) # split path by '/'\nlabels = pd.read_csv(path+'train_labels.csv')\ntrain = train.merge(labels, on='id') # merge labels and path\n\ntest = pd.DataFrame({'path':glob(os.path.join(test_dir,'*.tif'))})\ntest['id'] = test.path.map(lambda x: x.split('/')[4].split('.')[0])  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Preview the Dataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the dimensions of the dataset.\nrows = train.shape[0]\ncolumns = train.shape[1]\nprint('Total Number of Features: ', columns)\nprint('Total Number of Instances: ', rows)\n# Preview the first 10 instances.\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the dimensions of the dataset.\nrows = test.shape[0]\ncolumns = test.shape[1]\nprint('Total Number of Features: ', columns)\nprint('Total Number of Instances: ', rows)\n# Preview the first 10 instances.\ntest.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(N,df):\n    '''\n    This functions loads N images using the dataframe df\n    '''\n    #为每个image分配一个96*96*3的numpy array,像素范围是[0,255]\n    X = np.zeros([N,96,96,3],dtype=np.uint8) \n    #将label列转为numpy array\n    y = np.squeeze(df.as_matrix(columns=['label']))[0:N]  #移除掉1维的列\n    #迭代读取图像,tdqm 用于在notebook显示进度条\n    for i, row in tqdm_notebook(df.iterrows(), total=N):\n        if i == N:\n            break\n        X[i] = cv2.imread(row['path'])\n          \n    return X,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load 10k images\nN=10000\nX,y = load_data(N,train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.Exploratory Data Analysis (EDA)\n\nThe purpose of this EDA is to\n\n- Take a look at the images\n- Understand the distribution of the two classes (no cancer cells / cancer cells)\n- Have a look at some image features (RGB channel distributions, mean brightness)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 展示一些示例图像\nfig = plt.figure(figsize=(10, 4), dpi=150)  # 宽10英寸,高4英寸,分辨率150\nnp.random.seed(100) #we can use the seed to get a different set of random images\n\nfor plotNr,idx in enumerate(np.random.randint(0,N,8)):  # 随机产生8幅图像\n    ax = fig.add_subplot(2, 8//2, plotNr+1, xticks=[], yticks=[]) #add subplots\n    plt.imshow(X[idx]) #plot image\n    ax.set_title('Label: ' + str(y[idx])) #show the label corresponding to the image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 查看数据分布情况(数据不是均匀分布的话,可以考虑over- and undersampling)\nfig = plt.figure(figsize=(4, 2),dpi=150)\nplt.bar([1,0], [(y==0).sum(), (y==1).sum()]) #plot a bar chart of the label frequency\nplt.xticks([1,0],[\"Negative (N={})\".format((y==0).sum()),\"Positive (N={})\".format((y==1).sum())]) # ([索引],[labels])\nplt.ylabel(\"# of samples\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 查看每个类标签的情况\npositive_samples = X[y == 1]\nnegative_samples = X[y == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 比较RGB每个信道的像素值分布情况\nnr_of_bins = 256 #each possible pixel value will get a bin in the following histograms\nfig,axs = plt.subplots(4,2,sharey=True,figsize=(8,8),dpi=150)  # 4行2列的图\n\n#RGB channels\naxs[0,0].hist(positive_samples[:,:,:,0].flatten(),bins=nr_of_bins,density=True)  # 0表示的是RED信道\naxs[0,1].hist(negative_samples[:,:,:,0].flatten(),bins=nr_of_bins,density=True)  \naxs[1,0].hist(positive_samples[:,:,:,1].flatten(),bins=nr_of_bins,density=True)  # 1表示的是GREEN信道\naxs[1,1].hist(negative_samples[:,:,:,1].flatten(),bins=nr_of_bins,density=True)\naxs[2,0].hist(positive_samples[:,:,:,2].flatten(),bins=nr_of_bins,density=True)  # 2表示的是BLUE信道\naxs[2,1].hist(negative_samples[:,:,:,2].flatten(),bins=nr_of_bins,density=True)\n\n#All channels\naxs[3,0].hist(positive_samples.flatten(),bins=nr_of_bins,density=True)\naxs[3,1].hist(negative_samples.flatten(),bins=nr_of_bins,density=True)\n\n#Set image labels\naxs[0,0].set_title(\"Positive samples (N =\" + str(positive_samples.shape[0]) + \")\");\naxs[0,1].set_title(\"Negative samples (N =\" + str(negative_samples.shape[0]) + \")\");\naxs[0,1].set_ylabel(\"Red\",rotation='horizontal',labelpad=35,fontsize=12)    # 设置Y轴标签,并转为水平\naxs[1,1].set_ylabel(\"Green\",rotation='horizontal',labelpad=35,fontsize=12)\naxs[2,1].set_ylabel(\"Blue\",rotation='horizontal',labelpad=35,fontsize=12)\naxs[3,1].set_ylabel(\"RGB\",rotation='horizontal',labelpad=35,fontsize=12)\nfor i in range(4):\n    axs[i,0].set_ylabel(\"Relative frequency\")\naxs[3,0].set_xlabel(\"Pixel value\")\naxs[3,1].set_xlabel(\"Pixel value\")\nfig.tight_layout()    # 自动调整绘图窗口","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Negative samples seem to have higher, i.e. brighter, pixel values in general and especially in the green color channel.\n- Interestingly, the positive samples have a darker green channel than red and blue while this is not true for the negative samples. However, very dark pixels are for both sample sets mostly only present in the green channel.\n- Furthermore, note the relatively high frequency of the pixel value 255. Looking at the data above we can see, that these can likely be attributed to the bright white image regions present in some images. They seem to be present in both positive and negative samples similarly frequently."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 查看图像的平均亮度(图像像素值的平均数)\nnr_of_bins = 64 #we use a bit fewer bins to get a smoother image\nfig,axs = plt.subplots(1,2,sharey=True, sharex = True, figsize=(8,2),dpi=150)    # 1行2列\naxs[0].hist(np.mean(positive_samples,axis=(1,2,3)),bins=nr_of_bins,density=True)\naxs[1].hist(np.mean(negative_samples,axis=(1,2,3)),bins=nr_of_bins,density=True)\naxs[0].set_title(\"Mean brightness, positive samples\");\naxs[1].set_title(\"Mean brightness, negative samples\");\naxs[0].set_xlabel(\"Image mean brightness\")\naxs[1].set_xlabel(\"Image mean brightness\")\naxs[0].set_ylabel(\"Relative frequency\")\naxs[1].set_ylabel(\"Relative frequency\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution of mean brightness for the positive samples looks almost like a normal distribution around a brightness of 150. The negative samples, however, seem to follow some bimodal distribution with peaks around 140 and 225.  \n\n#### Conclusions:  \n- There are some easily spotted differences in the distributions of pixel values and mean image brightness between positive and negative samples. This is good, because whatever model we will use can likely use this.\n- Some of the images seem to contain very bright regions, which are likely artifacts of the recording process. We might have to find a way to deal with them. They are almost equally distributed between positive and negative samples and, hence, probably not easily usable as a feature.\n- We have about 50% more negative than positive samples. This might require adjustments."},{"metadata":{},"cell_type":"markdown","source":"# 4. Define the model "},{"metadata":{"trusted":true},"cell_type":"code","source":"# 载入所有的data\nN = train[\"path\"].size # get the number of images in the training data set\nX,y = load_data(N=N,df=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use the garbage collector and unbind some variables to free up space in our RAM.\n# Collect garbage\npositives_samples = None\nnegative_samples = None\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 分割data为训练集和验证集\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width = 96\nimg_height = 96\nnbr_train_samples = len(X_train)\nnbr_validation_samples = len(X_test)\nbatch_size = 32\n\n# this is the augmentation configuration we will use for training\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.1,\n        zoom_range=0.1,\n        rotation_range=10.,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        horizontal_flip=True)\n\n# this is the augmentation configuration we will use for validation:\n# only rescaling\nval_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow(\n        X_train, y_train,\n#         target_size = (img_width, img_height),\n        batch_size = batch_size,\n        shuffle = True)\n\nvalidation_generator = val_datagen.flow(\n        X_test, y_test,\n#         target_size=(img_width, img_height),\n        batch_size=batch_size,\n        shuffle = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#just some network parameters, see above link regarding the layers for details\nkernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\n\n#dropout is used for regularization here with a probability of 0.3 for conv layers, 0.5 for the dense layer at the end\ndropout_conv = 0.3\ndropout_dense = 0.5\n\n#initialize the model\nmodel = Sequential()\n\n#now add layers to it\n\n#conv block 1\nmodel.add(Conv2D(first_filters, kernel_size, input_shape = (96, 96, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(first_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\n#conv block 2\nmodel.add(Conv2D(second_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(second_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\n#conv block 3\nmodel.add(Conv2D(third_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(third_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\n#a fully connected (also called dense) layer at the end\nmodel.add(Flatten())\nmodel.add(Dense(256, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(dropout_dense))\n\n#finally convert to values of 0 to 1 using the sigmoid activation function\nmodel.add(Dense(1, activation = \"sigmoid\"))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Evaluate the model "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Further, we will use binary crossentropy as loss function and the Adam optimizer. We set the learning rate of 0.001 for now.\nmodel.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.Adam(0.001), \n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n\nmodel.fit_generator(\n                train_generator,\n                steps_per_epoch=STEP_SIZE_TRAIN,\n                epochs=15,\n                validation_data=validation_generator,\n                validation_steps=STEP_SIZE_VALID)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make a prediction\ny_pred_keras = model.predict_generator(test_gen, steps=len(df_val), verbose=1)\nfpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\nauc_keras = auc(fpr_keras, tpr_keras)\nauc_keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot ROC Curve\nplt.figure(1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Predict and submit \"submission.csv\" file"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = None\ny = None\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_files = glob(os.path.join(test_dir,'*.tif')) #find the test file names\nsubmission = pd.DataFrame() #create a dataframe to hold results\nfile_batch = 5000 #we will predict 5000 images at a time\nmax_idx = len(test_files) #last index to use\nfor idx in range(0, max_idx, file_batch): #iterate over test image batches\n    print(\"Indexes: %i - %i\"%(idx, idx+file_batch))\n    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]}) #add the filenames to the dataframe\n    test_df['id'] = test_df.path.map(lambda x: x.split('/')[3].split(\".\")[0]) #add the ids to the dataframe\n    test_df['image'] = test_df['path'].map(cv2.imread) #read the batch\n    K_test = np.stack(test_df[\"image\"].values) #convert to numpy array\n    predictions = model.predict(K_test,verbose = 1) #predict the labels for the test data\n    test_df['label'] = predictions #store them in the dataframe\n    submission = pd.concat([submission, test_df[[\"id\", \"label\"]]])\n    \nsubmission.head() #display first lines","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index = False, header = True) #create the submission file","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}